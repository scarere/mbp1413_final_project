{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data\n",
    "\n",
    "This notebook:\n",
    "- loads the raw images from the kaggle dataset\n",
    "- Converts them to a uniform size without distorting them\n",
    "- Generates the mask images for the test and validation images given the encoded solutions\n",
    "- Packages the images, their masks and the image id's into a dictionary and saves them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = 'kaggle_raw/stage2_test_final'\n",
    "val_dir = 'kaggle_raw/stage1_test'\n",
    "train_dir = 'kaggle_raw/stage1_train'\n",
    "train_mask_csv = 'kaggle_raw/stage1_train_labels_withmeta.csv'\n",
    "val_mask_csv = 'kaggle_raw/stage1_solution.csv'\n",
    "test_mask_csv = 'kaggle_raw/stage2_solution_final.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from imageio import imread\n",
    "import pandas as pd\n",
    "import os\n",
    "from create_masks import CreateMask\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from skimage.transform import rescale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_2_square(img, new_size=128):\n",
    "    '''Crops and resizes an image into a square image without distorting\n",
    "    the contents of the image.\n",
    "\n",
    "    Args:\n",
    "        img: a numpy array ot tuple containing the image\n",
    "        new_size (int): An integer representing the length and width\n",
    "            of the ouput images\n",
    "\n",
    "    Returns:\n",
    "        output_images (list): A list containing the output images. If an\n",
    "            image is highly rectangular, then it is split into multiple\n",
    "            sub images in order to preserve as much data as possible\n",
    "    '''\n",
    "    img = np.array(img)\n",
    "    dim = img.shape\n",
    "    \n",
    "    if (dim[0] > dim[1]):\n",
    "        num_splits = int(dim[0]/dim[1] + 0.5)\n",
    "        step = int(dim[0]/num_splits)\n",
    "        img_list = [img[step*i: step*(i + 1), :] for i in range(num_splits)]\n",
    "    else:\n",
    "        num_splits = int(dim[1]/dim[0] + 0.5)\n",
    "        step = int(dim[1]/num_splits)\n",
    "        img_list = [img[:, step*i: step*(i + 1)] for i in range(num_splits)]\n",
    "    \n",
    "    output_images = []\n",
    "    for im in img_list:\n",
    "        # Scale the smaller dimension to the exact desired size, and crop the excess\n",
    "        scale = new_size/np.min(im.shape[0:2])\n",
    "        if len(dim) == 3:\n",
    "            im = rescale(im, scale=(scale, scale, 1))\n",
    "        else:\n",
    "            im = rescale(im, scale=scale)\n",
    "        im = im[:new_size, :new_size]\n",
    "        output_images.append(im)\n",
    "\n",
    "    return output_images\n",
    "\n",
    "def add_info_to_train_csv(img_dir, labels_csv, save_path):\n",
    "    labels = pd.read_csv(labels_csv)\n",
    "    unique_ids = labels['ImageId'].unique()\n",
    "    rows = []\n",
    "    for id in tqdm(unique_ids):\n",
    "        img = imread(os.path.join(img_dir, id, 'images', id + '.png'))\n",
    "        vals = labels.loc[labels['ImageId'] == id]['EncodedPixels'].values\n",
    "        for val in vals:\n",
    "            rows.append([id, val, img.shape[0], img.shape[1], 'Public'])\n",
    "    df = pd.DataFrame(rows, columns=['ImageId', 'EncodedPixels', 'Height', 'Width', 'Usage'])\n",
    "    df.to_csv(save_path, index=False)\n",
    "\n",
    "\n",
    "def get_data(img_dir, labels_csv):\n",
    "    print('Generating Masks')\n",
    "    masks = CreateMask().generate_masks(labels_csv, iterator=tqdm)\n",
    "    rows = []\n",
    "    print('Processing Images')\n",
    "    for i, row in tqdm(masks.iterrows(), total=len(masks.index)):\n",
    "        id = row['ImageId']\n",
    "        mask = row['Mask']\n",
    "        img = imread(os.path.join(img_dir, id, 'images', id + '.png'), pilmode='RGB')\n",
    "        square_imgs = img_2_square(img)\n",
    "        square_masks = img_2_square(mask)\n",
    "        for i in range(len(square_imgs)):\n",
    "            rows.append([id, square_imgs[i], square_masks[i], len(square_imgs)])\n",
    "    \n",
    "    return pd.DataFrame(rows, columns=['image_id', 'image', 'mask', 'num_splits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Masks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9086e560e6041a5b9b87d6f8c9952c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Images\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c5a1126d47f4968a18054f8e8af885a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (676, 4)\n"
     ]
    }
   ],
   "source": [
    "#add_info_to_train_csv(train_dir, labels_csv='kaggle_raw/stage1_train_labels.csv', save_path='kaggle_raw/stage1_train_labels_withmeta.csv')\n",
    "train_data = get_data(train_dir, train_mask_csv)\n",
    "print('Shape: ', (len(train_data.index), len(train_data.columns)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Masks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e12da4f6e54b6faa1bda97fe822fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Images\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7248437baa9545f88284ec7e4647ca7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (82, 4)\n"
     ]
    }
   ],
   "source": [
    "val_data = get_data(val_dir, val_mask_csv)\n",
    "print('Shape: ', (len(val_data.index), len(val_data.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Masks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16b1efc04d2a4205850a4d1d3a132171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3019 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Images\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c63d16cc5ed54fd3a3b93772a4aa6895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/106 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (116, 4)\n"
     ]
    }
   ],
   "source": [
    "test_data = get_data(test_dir, test_mask_csv)\n",
    "print('Shape: ', (len(test_data.index), len(test_data.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False\n",
    "if save:\n",
    "    torch.save(train_data, 'undistorted/train.pt')\n",
    "    torch.save(val_data, 'undistorted/val.pt')\n",
    "    torch.save(test_data, 'undistorted/test.pt')\n",
    "    print('Data Saved')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d3a9543aec2f8534bb24b8aeb6f7a90e62cc17ac68d0ab0f603f0d4f81ac0ecc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 ('nuclei-seg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
