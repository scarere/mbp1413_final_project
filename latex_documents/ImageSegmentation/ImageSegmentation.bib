
@inproceedings{lalonde_capsules_2018,
	address = {Amsterdam, Netherlands},
	title = {Capsules for {Object} {Segmentation}},
	url = {http://arxiv.org/abs/1804.04241},
	abstract = {Convolutional neural networks (CNNs) have shown remarkable results over the last several years for a wide range of computer vision tasks. A new architecture recently introduced by Sabour et al. [2017], referred to as a capsule networks with dynamic routing, has shown great initial results for digit recognition and small image classiﬁcation. The success of capsule networks lies in their ability to preserve more information about the input by replacing max-pooling layers with convolutional strides and dynamic routing, allowing for preservation of part-whole relationships in the data. This preservation of the input is demonstrated by reconstructing the input from the output capsule vectors. Our work expands the use of capsule networks to the task of object segmentation for the ﬁrst time in the literature. We extend the idea of convolutional capsules with locally-connected routing and propose the concept of deconvolutional capsules. Further, we extend the masked reconstruction to reconstruct the positive input class. The proposed convolutionaldeconvolutional capsule network, called SegCaps, shows strong results for the task of object segmentation with substantial decrease in parameter space. As an example application, we applied the proposed SegCaps to segment pathological lungs from low dose CT scans and compared its accuracy and efﬁciency with other U-Net-based architectures. SegCaps is able to handle large image sizes (512 × 512) as opposed to baseline capsules (typically less than 32 × 32). The proposed SegCaps reduced the number of parameters of U-Net architecture by 95.4\% while still providing a better segmentation accuracy.},
	language = {en},
	urldate = {2020-10-15},
	booktitle = {{arXiv}:1804.04241 [cs, stat]},
	author = {LaLonde, Rodney and Bagci, Ulas},
	month = apr,
	year = {2018},
	note = {arXiv: 1804.04241},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Deep learning, Computer vision, Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Statistics - Machine Learning, Dynamic Routing},
	file = {LaLonde and Bagci - 2018 - Capsules for Object Segmentation.pdf:files/944/LaLonde and Bagci - 2018 - Capsules for Object Segmentation.pdf:application/pdf},
}

@article{afshar_capsule_2018,
	title = {Capsule {Networks} for {Brain} {Tumor} {Classification} based on {MRI} {Images} and {Course} {Tumor} {Boundaries}},
	url = {http://arxiv.org/abs/1811.00597},
	abstract = {According to official statistics, cancer is considered as the second leading cause of human fatalities. Among different types of cancer, brain tumor is seen as one of the deadliest forms due to its aggressive nature, heterogeneous characteristics, and low relative survival rate. Determining the type of brain tumor has significant impact on the treatment choice and patient's survival. Human-centered diagnosis is typically error-prone and unreliable resulting in a recent surge of interest to automatize this process using convolutional neural networks (CNNs). CNNs, however, fail to fully utilize spatial relations, which is particularly harmful for tumor classification, as the relation between the tumor and its surrounding tissue is a critical indicator of the tumor's type. In our recent work, we have incorporated newly developed CapsNets to overcome this shortcoming. CapsNets are, however, highly sensitive to the miscellaneous image background. The paper addresses this gap. The main contribution is to equip CapsNet with access to the tumor surrounding tissues, without distracting it from the main target. A modified CapsNet architecture is, therefore, proposed for brain tumor classification, which takes the tumor coarse boundaries as extra inputs within its pipeline to increase the CapsNet's focus. The proposed approach noticeably outperforms its counterparts.},
	urldate = {2020-12-13},
	journal = {arXiv:1811.00597 [cs]},
	author = {Afshar, Parnian and Plataniotis, Konstantinos N. and Mohammadi, Arash},
	month = nov,
	year = {2018},
	note = {arXiv: 1811.00597},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, ⛔ No DOI found},
	file = {arXiv Fulltext PDF:files/1135/Afshar et al. - 2018 - Capsule Networks for Brain Tumor Classification ba.pdf:application/pdf;arXiv.org Snapshot:files/1136/1811.html:text/html},
}
