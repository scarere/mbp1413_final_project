{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-02-18T21:57:10.860290Z","iopub.status.busy":"2022-02-18T21:57:10.859899Z","iopub.status.idle":"2022-02-18T21:57:26.561299Z","shell.execute_reply":"2022-02-18T21:57:26.560509Z","shell.execute_reply.started":"2022-02-18T21:57:10.860217Z"},"trusted":true},"outputs":[],"source":["# Install required packages\n","\n","# !pip install kornia\n","# !pip install torchmetrics\n","\n","# Set some parameters\n","\n","class Argument():\n","    def __init__(self):\n","        self.base_dir = '/kaggle/input/segmentation-dataset/'\n","        self.save_dir = '/kaggle/working/'\n","        self.IMG_WIDTH = 128\n","        self.IMG_HEIGHT = 128\n","        self.IMG_CHANNELS = 3\n","        self.width_out = 128\n","        self.height_out = 128\n","        self.batch_size = 32\n","        self.learning_rate = 0.01\n","        self.epochs = 100\n","        self.epoch_lapse = 10\n","        self.threshold = 0.33\n","        self.sample_size = None\n","        self.ishybrid = False\n","        self.isAttention = False\n","        self.attn_type = 'cosine' # 'cosine', regular_pointwise', 'regular_full', 'regular_full_dim_add' 'channel_attention'\n","        self.use_split_data = True\n","        self.power = 2\n","        self.is_swap_coeffs = False\n","        self.is_train_data_aug = False\n","        self.is_apply_color_jitter = False\n","        self.save_model = True\n","\n","args = Argument()"]},{"cell_type":"code","execution_count":4,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-02-18T21:57:54.397041Z","iopub.status.busy":"2022-02-18T21:57:54.396724Z","iopub.status.idle":"2022-02-18T22:10:15.992715Z","shell.execute_reply":"2022-02-18T22:10:15.992018Z","shell.execute_reply.started":"2022-02-18T21:57:54.397001Z"},"trusted":true},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/segmentation-dataset/'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/Users/scarere/Documents/UofT/OneDrive-UofT/mbp1413_final_project/code/training_scripts/train_baselines_sayan.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/scarere/Documents/UofT/OneDrive-UofT/mbp1413_final_project/code/training_scripts/train_baselines_sayan.ipynb#ch0000001?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/scarere/Documents/UofT/OneDrive-UofT/mbp1413_final_project/code/training_scripts/train_baselines_sayan.ipynb#ch0000001?line=1'>2</a>\u001b[0m os\u001b[39m.\u001b[39mchdir(args\u001b[39m.\u001b[39mbase_dir)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/scarere/Documents/UofT/OneDrive-UofT/mbp1413_final_project/code/training_scripts/train_baselines_sayan.ipynb#ch0000001?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/scarere/Documents/UofT/OneDrive-UofT/mbp1413_final_project/code/training_scripts/train_baselines_sayan.ipynb#ch0000001?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrandom\u001b[39;00m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/segmentation-dataset/'"]}],"source":["import os\n","os.chdir(args.base_dir)\n","import sys\n","import random\n","import warnings\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from tqdm import tqdm\n","from itertools import chain\n","from sklearn.model_selection import train_test_split\n","import torch\n","\n","from utils.loss_utils import *\n","from utils.model_utils import *\n","from utils.dataset_train_val import Dataset_train_val\n","from utils.training_validation_utils import *\n","from utils.plotutils import *\n","\n","\n","warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n","seed = 42\n","random.seed = seed\n","np.random.seed = seed\n","\n","use_gpu = torch.cuda.is_available()\n","dtv = Dataset_train_val(args.batch_size, use_gpu)\n","\n","def create_model_name(args):\n","    if args.ishybrid == True:\n","        if args.is_swap_coeffs == True:\n","            model_name = 'unet_hybrid_power'+str(args.power)+'_swap_coeffs'\n","        else:\n","            model_name = 'unet_hybrid_power'+str(args.power)\n","    else:\n","        if args.isAttention == True:\n","            model_name = 'unet_'+args.attn_type+'_attn'\n","        else:\n","            model_name = 'unet_no_attn'\n","    if args.is_train_data_aug == True:\n","        model_name = model_name + '_augmentation'\n","    return model_name + '.pt'\n","\n","if args.use_split_data == True:\n","    x_train = torch.load('x_train_split.pt')\n","    x_val = torch.load('x_val_split.pt')\n","    y_train = torch.load('y_train_split.pt')\n","    y_val = torch.load('y_val_split.pt')\n","    x_test = torch.load('x_test.pt')\n","\n","else:\n","    x_train, x_val, y_train, y_val, x_test = dtv.load_train_val_test('x_train.pt', 'y_train.pt', 'x_test.pt', split_ratio=0.2)\n","# print(x_train.shape,x_val.shape,x_test.shape)\n","\n","# Train Model\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from tqdm import trange\n","from time import sleep\n","\n","if args.ishybrid == True:\n","    print('Training Hybrid Net')\n","    flatten_arg = False # for hybrid net\n","    unet = Hybrid_Net(img_ch=3,output_ch=1) \n","    criterion = DiceBCELossModified(full_flatten=flatten_arg) # nn.CrossEntropyLoss() # TverskyBCELoss()\n","else:\n","    if args.isAttention == True:\n","        print('Training Attention U-Net')\n","        unet = AttU_Net(img_ch=3,output_ch=1, attn_type = args.attn_type)\n","    else:\n","        print('Training Vanilla U-Net')\n","        unet = UNet(in_channel=3,out_channel=1)\n","    criterion = DiceBCELoss() # nn.CrossEntropyLoss() # TverskyBCELoss()\n","\n","if use_gpu:\n","    unet = unet.cuda()\n","optimizer = optim.SGD(unet.parameters(), lr = args.learning_rate, momentum=0.99)\n","train_losses, val_losses = Training_Validation(ishybrid=args.ishybrid,power=args.power,swap_coeffs=args.is_swap_coeffs,is_train_data_aug=args.is_train_data_aug,is_apply_color_jitter=args.is_apply_color_jitter).train_valid(unet, x_train , y_train, x_val, y_val, optimizer, criterion, args.batch_size, dtv, use_gpu, epochs = args.epochs, epoch_lapse = args.epoch_lapse)\n","\n","if args.save_model == True:\n","    torch.save(unet,args.save_dir+create_model_name(args))"]},{"cell_type":"markdown","metadata":{},"source":["**Train Model**"]},{"cell_type":"markdown","metadata":{},"source":["**Plot Results**"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-02-18T22:10:15.995102Z","iopub.status.busy":"2022-02-18T22:10:15.994397Z","iopub.status.idle":"2022-02-18T22:10:24.047872Z","shell.execute_reply":"2022-02-18T22:10:24.047272Z","shell.execute_reply.started":"2022-02-18T22:10:15.995062Z"},"trusted":true},"outputs":[],"source":["allp = Allplots()\n","\n","if args.ishybrid == True:\n","    allp.plot_losses(train_losses, [])\n","else:\n","    allp.plot_losses(train_losses, val_losses)\n","\n","allp.plot_examples(unet, x_train, y_train, 12, ishybrid=args.ishybrid)\n","\n","allp.plot_examples(unet, x_val, y_val, 12, ishybrid=args.ishybrid)"]},{"cell_type":"markdown","metadata":{},"source":["**Display Metrics**"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-02-18T22:10:24.049834Z","iopub.status.busy":"2022-02-18T22:10:24.049383Z","iopub.status.idle":"2022-02-18T22:10:35.116570Z","shell.execute_reply":"2022-02-18T22:10:35.115785Z","shell.execute_reply.started":"2022-02-18T22:10:24.049798Z"},"trusted":true},"outputs":[],"source":["from utils.segment_metrics import IOU_eval\n","\n","iou_ev = IOU_eval(ishybrid=args.ishybrid)\n","\n","print('Training')\n","iou_t, iou_t_indices = iou_ev.iou_evaluate(unet, x_train, y_train)\n","allp.plot_best(unet, x_train, datay=y_train, indx=np.argsort(iou_t)[-5:], index_ranks=iou_t_indices, ishybrid=args.ishybrid)\n","\n","print('Validation')\n","iou_v, iou_v_indices = iou_ev.iou_evaluate(unet, x_val, y_val)\n","allp.plot_best(unet, x_val, datay=y_val, indx=np.argsort(iou_v)[-5:], index_ranks=iou_v_indices, ishybrid=args.ishybrid)\n","\n","print('Testing')\n","allp.plot_best(unet, x_test, datay=None, indx=np.random.permutation(65)[:5], index_ranks=np.zeros(5), ishybrid=args.ishybrid)\n","\n","print('Train Mean IOU: '+str(np.mean(iou_t))+', Valid Mean IOU: '+str(np.mean(iou_v)))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"}},"nbformat":4,"nbformat_minor":4}
